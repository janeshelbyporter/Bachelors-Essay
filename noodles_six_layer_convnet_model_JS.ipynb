{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img, load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default settings\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_dir = '/Users/Janeshelbyporter/Documents/OneDrive-CofC/BE/Image-Recognition-with-Deep-Learning-master/data/noodles/train'\n",
    "validate_dir = '/Users/Janeshelbyporter/Documents/OneDrive-CofC/BE/Image-Recognition-with-Deep-Learning-master/data/noodles/validate'\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n"
     ]
    }
   ],
   "source": [
    "# get number of images in training directory\n",
    "nb_train_samples = 0\n",
    "for r, dirs, files in os.walk(train_dir):\n",
    "    for dr in dirs:\n",
    "        nb_train_samples += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "print(nb_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# get number of images in validation directory\n",
    "nb_validate_samples = 0\n",
    "for r, dirs, files in os.walk(validate_dir):\n",
    "    for dr in dirs:\n",
    "        nb_validate_samples += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "print(nb_validate_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing for training\n",
    "train_datagen =  ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    fill_mode = 'nearest',\n",
    "    horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing for validation\n",
    "validate_datagen =  ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    fill_mode = 'nearest',\n",
    "    horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 315 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generate and store training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# generate and store validation data\n",
    "validate_generator = validate_datagen.flow_from_directory(\n",
    "    validate_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def convnet_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                    input_shape=(3, img_width, img_height),\n",
    "                    activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                    activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                    activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate CNN model\n",
    "model_final = convnet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lr = 0.01\n",
    "sgd = SGD(learning_rate=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 09:25:43.697027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 2.4252 - accuracy: 0.4698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 09:26:00.737943: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 18s 1s/step - loss: 2.4252 - accuracy: 0.4698 - val_loss: 1.0405 - val_accuracy: 0.4444 - lr: 0.0100\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.8179 - accuracy: 0.4476 - val_loss: 1.2974 - val_accuracy: 0.4444 - lr: 0.0100\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.8026 - accuracy: 0.4476 - val_loss: 1.3981 - val_accuracy: 0.4444 - lr: 0.0100\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 12s 1s/step - loss: 1.7739 - accuracy: 0.4476 - val_loss: 1.1289 - val_accuracy: 0.4444 - lr: 0.0100\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 11s 1s/step - loss: 1.7700 - accuracy: 0.4476 - val_loss: 1.4617 - val_accuracy: 0.4444 - lr: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e6faca90>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "# #     steps_per_epoch = nb_train_samples / batch_size,\n",
    "    validation_data = validate_generator,\n",
    "#     validation_steps = nb_validate_samples / batch_size,\n",
    "    class_weight={0: 10., 1: 1.},\n",
    "    callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
